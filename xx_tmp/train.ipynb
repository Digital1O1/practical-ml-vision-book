{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import sys, re, math\n",
    "sys.path.append('../../tensorflow-model-garden') # Path to Tensorflow model garden installation directory\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pprint as pp\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "print(\"Tensorflow version\", tf.__version__)\n",
    "\n",
    "# Tensorflow Model Garden imports\n",
    "from official.vision.detection.configs import factory as tf_garden_config_factory\n",
    "from official.modeling.hyperparams import params_dict as tf_garden_params_dict\n",
    "from official.vision.detection.modeling import factory as tf_garden_model_factory\n",
    "from official.vision.detection.dataloader import input_reader as tf_garden_input_reader\n",
    "from official.vision.detection.dataloader import mode_keys as tf_garden_mode_keys\n",
    "from official.vision.detection.executor.detection_executor import DetectionDistributedExecutor as tf_garden_training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some flags are mandatory in Tensorflow Model Garden. This is unfortunate. Use default values for now.\n",
    "from absl import flags\n",
    "from official.utils import hyperparams_flags\n",
    "hyperparams_flags.initialize_common_flags()\n",
    "flags.FLAGS([\"\"])\n",
    "\n",
    "%matplotlib inline\n",
    "# official.vision.detection.executor.detection_executor also imports\n",
    "# official.vision.detection.utils.object_detection.vusualization_utils.py\n",
    "# which messes up the matplotlib backend. This magic resets it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPU / GPU detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: martin-tpuv3-8-tf24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: martin-tpuv3-8-tf24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "try: # detect TPUs\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    #policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    #tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "except ValueError: # detect GPUs or multi-GPU machines\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 TFRecord files.\n",
      "15376 images\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH_PATTERN = 'gs://practical-ml-vision-book/arthropod_detection_tfr/size_w1024px/*.tfrec'\n",
    "\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "\n",
    "MODEL_DIR = 'gs://ml1-demo-martin/arthropod_jobs'\n",
    "\n",
    "RAW_CLASSES = ['Lepidoptera', 'Hymenoptera', 'Hemiptera', 'Odonata', 'Diptera', 'Araneae', 'Coleoptera',\n",
    "               '_truncated', '_blurred', '_occluded', ]\n",
    "CLASSES = [klass for klass in RAW_CLASSES if klass not in ['_truncated', '_blurred', '_occluded']]\n",
    "\n",
    "#PAD_MAX_BOXES = 50\n",
    "\n",
    "# Lepidoptera = butterfies and moths\n",
    "# Hymenoptera = wasps, bees and ants\n",
    "# Hemiptera = true bugs (cicadas, aphids, shield bugs, ...)\n",
    "# Odonata = dragonflies\n",
    "# Diptera = fies\n",
    "# Araneae = spiders\n",
    "# Coleoptera = beetles\n",
    "\n",
    "# NOT IN DATASET\n",
    "# Orthoptera = grasshoppers\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "TRAIN_FILENAMES = tf.io.gfile.glob(DATA_PATH_PATTERN)\n",
    "print(f\"Found {len(TRAIN_FILENAMES)} TFRecord files.\")\n",
    "NB_TRAIN_IMAGES = count_data_items(TRAIN_FILENAMES)\n",
    "print(f\"{NB_TRAIN_IMAGES} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_decorations(ax):\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "\n",
    "def display_detections(images, offsets, resizes, detections, classnames, ground_truth_boxes=[]):\n",
    "    # scale and offset the detected boxes back to original image coordinates\n",
    "    boxes   = [[ (x,y,w,h)  for _, x, y, w, h, score, klass in detection_list] for detection_list in detections]\n",
    "    boxes   = [[ (x-ofs[1], y-ofs[0], w, h) for x,y,w,h in boxlist ] for boxlist, ofs in zip(boxes, offsets)]\n",
    "    boxes   = [[ (x*rsz, y*rsz, w*rsz, h*rsz) for x,y,w,h in boxlist ] for boxlist, rsz in zip(boxes, resizes)]\n",
    "    classes = [[ int(klass) for _, x, y, w, h, score, klass in detection_list] for detection_list in detections]\n",
    "    scores  = [[ score      for _, x, y, w, h, score, klass in detection_list] for detection_list in detections]\n",
    "    display_with_boxes(images, boxes, classes, scores, classnames, ground_truth_boxes)\n",
    "    \n",
    "    \n",
    "# images, boxes and classes must have the same number of elements\n",
    "# scores can be en empty list []. If it is not empty, it must also\n",
    "# have the same number of elements.\n",
    "# classnames is the list of possible classes (strings)\n",
    "def display_with_boxes(images, boxes, classes, scores, classnames, ground_truth_boxes=[]):\n",
    "    N = len(images)\n",
    "    sqrtN = int(math.ceil(math.sqrt(N)))\n",
    "    aspect = sum([im.shape[1]/im.shape[0] for im in images])/len(images) # mean aspect ratio of images\n",
    "    fig = plt.figure(figsize=(15,15/aspect), frameon=False)\n",
    "    \n",
    "    for k in range(N):\n",
    "        ax = plt.subplot(sqrtN, sqrtN, k+1)\n",
    "        no_decorations(ax)\n",
    "        plt.imshow(images[k])\n",
    "        \n",
    "        if ground_truth_boxes:\n",
    "            for box in ground_truth_boxes[k]:\n",
    "                x, y, w, h = (box[0], box[1], box[2]-box[0], box[3]-box[1]) # convert x1 y1 x2 y2 into xywh\n",
    "                #x, y, w, h = (box[0], box[1], box[2], box[3])\n",
    "                rect = mpl.patches.Rectangle((x, y),w,h,linewidth=4,edgecolor='#FFFFFFA0',facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        for i, (box, klass) in enumerate(zip(boxes[k], classes[k])):\n",
    "            x, y, w, h = (box[0], box[1], box[2]-box[0], box[3]-box[1]) # convert x1 y1 x2 y2 into xywh\n",
    "            #x, y, w, h = (box[0], box[1], box[2], box[3])\n",
    "            #label = classnames[klass-1] # predicted classes are 1-based\n",
    "            label = classnames[klass]\n",
    "            if scores:\n",
    "                label += ' ' + str(int(scores[k][i]*100)) + '%' \n",
    "            rect = mpl.patches.Rectangle((x, y),w,h,linewidth=4,edgecolor='#00000080',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            rect = mpl.patches.Rectangle((x, y),w,h,linewidth=2,edgecolor='#FFFF00FF',facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            plt.text(x, y, label, size=16, ha=\"left\", va=\"top\", color='#FFFF00FF',\n",
    "                     bbox=dict(boxstyle=\"round\", ec='#00000080', fc='#0000004E', linewidth=3) )\n",
    "            plt.text(x, y, label, size=16, ha=\"left\", va=\"top\", color='#FFFF00FF',\n",
    "                     bbox=dict(boxstyle=\"round\", ec='#FFFF00FF', fc='#0000004E', linewidth=1.5) )\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_to_max(x, max_n):\n",
    "#     pad_n = tf.maximum(max_n-len(x), 0)\n",
    "#     # padding are pairs of [before, after] nb paddings for each dimension\n",
    "#     padding0 = tf.convert_to_tensor([[0, pad_n]])\n",
    "#     paddings = tf.zeros([tf.rank(x)-1, 2], dtype=tf.int32)\n",
    "#     paddings = tf.concat([padding0, paddings], axis=0)\n",
    "#     return tf.pad(x, paddings)\n",
    "\n",
    "# def lookup_tags(tags, class_table):\n",
    "#     classes = class_table.lookup(tags)\n",
    "#     return classes\n",
    "\n",
    "# def pad_everything(image, name, boxes, tags, classes):\n",
    "#     nb_boxes = len(boxes)\n",
    "#     boxes = pad_to_max(boxes, PAD_MAX_BOXES)\n",
    "#     tags = pad_to_max(tags, PAD_MAX_BOXES)\n",
    "#     classes = pad_to_max(classes, PAD_MAX_BOXES)\n",
    "#     return image, name, boxes, tags, classes, nb_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tf_garden_config_factory.config_generator('retinanet')\n",
    "params_override = { 'architecture': {'backbone': 'spinenet',\n",
    "                                     'multilevel_features': 'identity',\n",
    "                                     'num_classes': 7,\n",
    "                                     'use_bfloat16': False},\n",
    "                    'spinenet': {'model_id': '49'},\n",
    "                  }\n",
    "params = tf_garden_params_dict.override_params_dict(params, params_override, is_strict=True)\n",
    "#pp.pprint(params.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = tf_garden_model_factory.model_generator(params)\n",
    "\n",
    "def create_model(params):\n",
    "    model = model_builder.build_model(params, mode=tf_garden_mode_keys.TRAIN)\n",
    "    return model\n",
    "\n",
    "train_input_fn = tf_garden_input_reader.InputFn(TRAIN_FILENAMES, params=params,\n",
    "                                                mode=tf_garden_mode_keys.TRAIN,\n",
    "                                                batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = int(strategy.num_replicas_in_sync + 7) // 8\n",
    "is_multi_host = (int(num_workers) >= 2)\n",
    "\n",
    "trainig_loop = tf_garden_training_loop(\n",
    "        strategy=strategy,\n",
    "        params=params,\n",
    "        model_fn=create_model,\n",
    "        loss_fn=model_builder.build_loss_fn,\n",
    "        is_multi_host=is_multi_host,\n",
    "        predict_post_process_fn=model_builder.post_processing,\n",
    "        trainable_variables_filter=model_builder.make_filter_trainable_variables_fn()\n",
    "    )\n",
    "\n",
    "# TODO: understand this...\n",
    "# in multihost mode, dataset.distribute_from_function is used instead of dataset.distribute\n",
    "#if is_multi_host:\n",
    "#      train_input_fn = functools.partial(\n",
    "#          train_input_fn,\n",
    "#          batch_size=params.train.batch_size // strategy.num_replicas_in_sync)\n",
    "\n",
    "# TODO: figure out outside automatic compilation for Tensorboard summaries on TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Detection: train metric is not an instance of tf.keras.metrics.Metric.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total loss is NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4d88d853a5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_TRAIN_IMAGES\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#init_checkpoint=model_builder.make_restore_checkpoint_fn(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     save_config=True)\n\u001b[0m",
      "\u001b[0;32m~/tensorflow-model-garden/official/modeling/training/distributed_executor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_input_fn, eval_input_fn, model_dir, total_steps, iterations_per_loop, train_metric_fn, eval_metric_fn, summary_writer_fn, init_checkpoint, custom_callbacks, continuous_eval, save_config)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total loss is NaN.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtrain_metric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total loss is NaN."
     ]
    }
   ],
   "source": [
    "result = trainig_loop.train(\n",
    "    train_input_fn=train_input_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    iterations_per_loop=100,\n",
    "    total_steps=NB_TRAIN_IMAGES//BATCH_SIZE,\n",
    "    #init_checkpoint=model_builder.make_restore_checkpoint_fn(),\n",
    "    save_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-4.m60",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-4:m60"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
