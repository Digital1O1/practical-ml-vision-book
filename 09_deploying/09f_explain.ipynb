{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "hiQ6zAoYhyaA",
    "outputId": "0acee878-1207-42c3-9bee-a594acd44365"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
       "  <td>\n",
       "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Explain predictions&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F09_deploying%2F09f_explain.ipynb&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F09_deploying%2F09f_explain.ipynb\">\n",
       "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n",
       "  </td>\n",
       "  </td>\n",
       "  <td>\n",
       "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09f_explain.ipynb\">\n",
       "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
       "  </td>\n",
       "  <td>\n",
       "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09f_explain.ipynb\">\n",
       "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
       "  </td>\n",
       "  <td>\n",
       "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/09_deploying/09f_explain.ipynb\">\n",
       "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
       "  </td>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "### change to reflect your notebook\n",
    "_nb_loc = \"09_deploying/09f_explain.ipynb\"\n",
    "_nb_title = \"Explain predictions\"\n",
    "\n",
    "### no need to change any of this\n",
    "_nb_safeloc = _nb_loc.replace('/', '%2F')\n",
    "md(\"\"\"\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name={1}&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F{2}&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F{2}\">\n",
    "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n",
    "  </td>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/{0}\">\n",
    "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n",
    "\"\"\".format(_nb_loc, _nb_title, _nb_safeloc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# Explain predictions\n",
    "\n",
    "In this notebook, we explain model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UOm2etrwYCs"
   },
   "source": [
    "## Enable GPU and set up helper functions\n",
    "\n",
    "This notebook and pretty much every other notebook in this repository\n",
    "will run faster if you are using a GPU.\n",
    "On Colab:\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- Select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "On Cloud AI Platform Notebooks:\n",
    "- Navigate to https://console.cloud.google.com/ai-platform/notebooks\n",
    "- Create an instance with a GPU or select your instance and add a GPU\n",
    "\n",
    "Next, we'll confirm that we can connect to the GPU with tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version' + tf.version.VERSION)\n",
    "print('Built with GPU support? ' + ('Yes!' if tf.test.is_built_with_cuda() else 'Noooo!'))\n",
    "print('There are {} GPUs'.format(len(tf.config.experimental.list_physical_devices(\"GPU\"))))\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with preprocess signature\n",
    "\n",
    "We start from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "\n",
    "MODEL_LOCATION='export/flowers_model3'  # will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from checkpoint and export a model that has desired signature\n",
    "CHECK_POINT_DIR='gs://practical-ml-vision-book/flowers_5_trained/chkpts'\n",
    "model = tf.keras.models.load_model(CHECK_POINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: export/flowers_model3/assets\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 345\n",
    "IMG_WIDTH = 345\n",
    "IMG_CHANNELS = 3\n",
    "CLASS_NAMES = 'daisy dandelion roses sunflowers tulips'.split()\n",
    "\n",
    "def preprocess(filename):\n",
    "    img_bytes = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS], dtype=tf.float32)])\n",
    "def xai_model(input_images):\n",
    "    batch_pred = model(input_images) # same as model.predict()\n",
    "    top_prob = tf.math.reduce_max(batch_pred, axis=[1])\n",
    "    pred_label_index = tf.math.argmax(batch_pred, axis=1)\n",
    "    pred_label = tf.gather(tf.convert_to_tensor(CLASS_NAMES), pred_label_index)\n",
    "    return {\n",
    "        'probability': top_prob,\n",
    "        'flower_type_int': pred_label_index,\n",
    "        'flower_type_str': pred_label\n",
    "    }\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
    "def xai_preprocess(filenames):\n",
    "    input_images = tf.map_fn(\n",
    "        preprocess,\n",
    "        filenames,\n",
    "        fn_output_signature=tf.float32\n",
    "    )\n",
    "    return {\n",
    "        # match the signature of xai_model\n",
    "        'input_images': input_images\n",
    "    }\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
    "def predict_filename(filenames):\n",
    "    preproc_output = xai_preprocess(filenames)\n",
    "    return xai_model(preproc_output['input_images'])\n",
    "\n",
    "shutil.rmtree('export', ignore_errors=True)\n",
    "os.mkdir('export')\n",
    "model.save(MODEL_LOCATION,\n",
    "          signatures={\n",
    "              'serving_default': predict_filename,\n",
    "              'xai_preprocess': xai_preprocess, # should be exactly what's supplied to model\n",
    "              'xai_model': xai_model # call the model\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['filenames'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: serving_default_filenames:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['flower_type_int'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall:0\n",
      "    outputs['flower_type_str'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall:1\n",
      "    outputs['probability'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall:2\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "signature_def['xai_model']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_images'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 345, 345, 3)\n",
      "        name: xai_model_input_images:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['flower_type_int'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall_1:0\n",
      "    outputs['flower_type_str'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall_1:1\n",
      "    outputs['probability'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: StatefulPartitionedCall_1:2\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "signature_def['xai_preprocess']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['filenames'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: xai_preprocess_filenames:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['input_images'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 345, 345, 3)\n",
      "        name: StatefulPartitionedCall_2:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          random/center_crop_input: TensorSpec(shape=(None, 345, 345, 3), dtype=tf.float32, name='random/center_crop_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {MODEL_LOCATION} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the new signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flower_type_int': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 0, 4, 4])>, 'flower_type_str': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'dandelion', b'dandelion', b'daisy', b'tulips', b'tulips'],\n",
      "      dtype=object)>, 'probability': <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.39833778, 0.9999609 , 0.9947188 , 0.95900667, 0.94177294],\n",
      "      dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "serving_fn = tf.keras.models.load_model(MODEL_LOCATION).signatures['serving_default']\n",
    "filenames = [\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/tulips/8713397358_0505cc0176_n.jpg'\n",
    "]\n",
    "pred = serving_fn(tf.convert_to_tensor(filenames))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fn = tf.keras.models.load_model(MODEL_LOCATION).signatures['xai_preprocess']\n",
    "filenames = [\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
    "]\n",
    "pred = serving_fn(tf.convert_to_tensor(filenames))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create explanation metadata\n",
    "\n",
    "We can use a Python API to create explanations.json or we can hand-create it.\n",
    "\n",
    "As a baseline, we'll use a random image (we could also use all zeros or all ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
    "import numpy as np\n",
    "\n",
    "export_path=MODEL_LOCATION  # save with model\n",
    "# We want to explain 'xai_model' signature.\n",
    "builder = SavedModelMetadataBuilder(\n",
    "    export_path,\n",
    "    signature_name='xai_model',\n",
    "    outputs_to_explain=['probability'])\n",
    "random_baseline = np.random.rand(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "builder.set_image_metadata(\n",
    "    'input_images',\n",
    "    input_baselines=[random_baseline.tolist()])\n",
    "builder.save_metadata(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"outputs\": {\n",
      "    \"probability\": {\n",
      "      \"output_tensor_name\": \"probability\"\n",
      "    }\n",
      "  },\n",
      "  \"inputs\": {\n",
      "    \"input_images\": {\n",
      "      \"input_tensor_name\": \"input_images\",\n",
      "      \"encoding\": \"identity\",\n",
      "      \"modality\": \"image\",\n",
      "      \"input_baselines\": [\n",
      "        [\n",
      "          [\n",
      "            [\n",
      "              0.9785163327444246,\n",
      "              0.9643898229957655,\n",
      "              0.420070782929297\n",
      "            ],\n",
      "            [\n"
     ]
    }
   ],
   "source": [
    "!head -20 {MODEL_LOCATION}/explanation_metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy explanation model to Cloud AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://export/flowers_model3/explanation_metadata.json [Content-Type=application/json]...\n",
      "Copying file://export/flowers_model3/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://export/flowers_model3/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://export/flowers_model3/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "- [4 files][ 25.6 MiB/ 25.6 MiB]                                                \n",
      "Operation completed over 4 objects/25.6 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r {MODEL_LOCATION} gs://ai-analytics-solutions/tmp/flowers_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying flowers_regional:ig from gs://ai-analytics-solutions/tmp/flowers_explanations\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "The model named flowers_regional already exists.\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Deleting already the existing model flowers_regional:ig ... \n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Deleting version [ig]......done.                                               \n",
      "Please run this script again if you don't see a Creating message ... \n",
      "Creating flowers_regional:ig --explanation-method integrated-gradients --num-integral-steps 25\n",
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "Explanations reflect patterns in your model, but don't necessarily reveal fundamental relationships about your data population. See https://cloud.google.com/ml-engine/docs/ai-explanations/limitations for more information.\n"
     ]
    }
   ],
   "source": [
    "!./caip_deploy_regional.sh --model_location {MODEL_LOCATION} #gs://ai-analytics-solutions/tmp/flowers_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting request.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile request.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"filenames\": \"gs://cloud-ml-data/img/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://cloud-ml-data/img/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://cloud-ml-data/img/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://cloud-ml-data/img/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://cloud-ml-data/img/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai-platform.predict) HTTP request failed. Response: {\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"Field: name Error: Online prediction is unavailable for this version. Please verify that CreateVersion has completed successfully.\",\n",
      "    \"status\": \"NOT_FOUND\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\n",
      "        \"fieldViolations\": [\n",
      "          {\n",
      "            \"field\": \"name\",\n",
      "            \"description\": \"Online prediction is unavailable for this version. Please verify that CreateVersion has completed successfully.\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict --region=us-central1 --model=flowers_regional --version=ig --json-request=request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duu8mX3iXANE"
   },
   "source": [
    "## License\n",
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
