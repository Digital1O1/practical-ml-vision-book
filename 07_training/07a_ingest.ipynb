{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "hiQ6zAoYhyaA",
    "outputId": "0acee878-1207-42c3-9bee-a594acd44365"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
       "  <td>\n",
       "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Writing an efficient ingest Loop&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F06_preprocessing%2F07a_ingest.ipynb&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F06_preprocessing%2F07a_ingest.ipynb\">\n",
       "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n",
       "  </td>\n",
       "  </td>\n",
       "  <td>\n",
       "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/06_preprocessing/07a_ingest.ipynb\">\n",
       "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
       "  </td>\n",
       "  <td>\n",
       "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/06_preprocessing/07a_ingest.ipynb\">\n",
       "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
       "  </td>\n",
       "  <td>\n",
       "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/06_preprocessing/07a_ingest.ipynb\">\n",
       "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
       "  </td>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "### change to reflect your notebook\n",
    "_nb_loc = \"07_training/07a_ingest.ipynb\"\n",
    "_nb_title = \"Writing an efficient ingest Loop\"\n",
    "\n",
    "### no need to change any of this\n",
    "_nb_safeloc = _nb_loc.replace('/', '%2F')\n",
    "md(\"\"\"\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name={1}&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F{2}&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F{2}\">\n",
    "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n",
    "  </td>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/{0}\">\n",
    "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n",
    "\"\"\".format(_nb_loc, _nb_title, _nb_safeloc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# Efficient Ingest\n",
    "\n",
    "In this notebook, we improve the training performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UOm2etrwYCs"
   },
   "source": [
    "## Enable GPU and set up helper functions\n",
    "\n",
    "This notebook and pretty much every other notebook in this repository\n",
    "will run faster if you are using a GPU.\n",
    "On Colab:\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- Select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "On Cloud AI Platform Notebooks:\n",
    "- Navigate to https://console.cloud.google.com/ai-platform/notebooks\n",
    "- Create an instance with a GPU or select your instance and add a GPU\n",
    "\n",
    "Next, we'll confirm that we can connect to the GPU with tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version2.3.1\n",
      "Built with GPU support? Yes!\n",
      "There are 2 GPUs\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version' + tf.version.VERSION)\n",
    "print('Built with GPU support? ' + ('Yes!' if tf.test.is_built_with_cuda() else 'Noooo!'))\n",
    "print('There are {} GPUs'.format(len(tf.config.experimental.list_physical_devices(\"GPU\"))))\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original code\n",
    "\n",
    "This is the original code, from [../06_preprocessing/06e_colordistortion.ipynb](../06_preprocessing/06e_colordistortion.ipynb)\n",
    "\n",
    "We have a few variations of creating a preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'    \n",
    "\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "\n",
    "IMG_HEIGHT = 448 # note *twice* what we used to have\n",
    "IMG_WIDTH = 448\n",
    "IMG_CHANNELS = 3\n",
    "CLASS_NAMES = 'daisy dandelion roses sunflowers tulips'.split()\n",
    "\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "    \n",
    "class _Preprocessor:    \n",
    "    def __init__(self):\n",
    "        # nothing to initialize\n",
    "        pass\n",
    "    \n",
    "    def read_from_tfr(self, proto):\n",
    "        feature_description = {\n",
    "            'image': tf.io.VarLenFeature(tf.float32),\n",
    "            'shape': tf.io.VarLenFeature(tf.int64),\n",
    "            'label': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'label_int': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "        }\n",
    "        rec = tf.io.parse_single_example(\n",
    "            proto, feature_description\n",
    "        )\n",
    "        shape = tf.sparse.to_dense(rec['shape'])\n",
    "        img = tf.reshape(tf.sparse.to_dense(rec['image']), shape)\n",
    "        label_int = rec['label_int']\n",
    "        return img, label_int\n",
    "    \n",
    "    def read_from_jpegfile(self, filename):\n",
    "        # same code as in 05_create_dataset/jpeg_to_tfrecord.py\n",
    "        img = tf.io.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img\n",
    "      \n",
    "    def preprocess(self, img):\n",
    "        return tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "def create_preproc_dataset_plain(pattern):\n",
    "    preproc = _Preprocessor()\n",
    "    trainds = tf.data.TFRecordDataset(\n",
    "        [filename for filename in tf.io.gfile.glob(pattern)],\n",
    "        compression_type='GZIP'\n",
    "    ).map(preproc.read_from_tfr).map(\n",
    "        lambda img, label: (preproc.preprocess(img), label)\n",
    "    )                             \n",
    "    return trainds\n",
    "\n",
    "# note: addition of AUTOTUNE to the map() calls\n",
    "def create_preproc_dataset_parallelmap(pattern):\n",
    "    preproc = _Preprocessor()\n",
    "    def _preproc_img_label(img, label):\n",
    "        return (preproc.preprocess(img), label)\n",
    "    trainds = (\n",
    "        tf.data.TFRecordDataset(\n",
    "            [filename for filename in tf.io.gfile.glob(pattern)],\n",
    "            compression_type='GZIP'\n",
    "        )\n",
    "        .map(preproc.read_from_tfr, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_preproc_img_label, num_parallel_calls=AUTOTUNE)\n",
    "    )\n",
    "    return trainds\n",
    "\n",
    "# note: splits the files into two halves and interleaves datasets\n",
    "def create_preproc_dataset_interleave(pattern, num_parallel=None):\n",
    "    preproc = _Preprocessor()\n",
    "    files = [filename for filename in tf.io.gfile.glob(pattern)]\n",
    "    if len(files) > 1:\n",
    "        print(\"Interleaving the reading of {} files.\".format(len(files)))\n",
    "        def _create_half_ds(x):\n",
    "            if x == 0:\n",
    "                half = files[:(len(files)//2)]\n",
    "            else:\n",
    "                half = files[(len(files)//2):]\n",
    "            return tf.data.TFRecordDataset(half,\n",
    "                                          compression_type='GZIP')\n",
    "        trainds = tf.data.Dataset.range(2).interleave(\n",
    "            _create_half_ds, num_parallel_calls=AUTOTUNE)\n",
    "    else:\n",
    "        trainds = tf.data.TFRecordDataset(files,\n",
    "                                         compression_type='GZIP')\n",
    "    def _preproc_img_label(img, label):\n",
    "        return (preproc.preprocess(img), label)\n",
    "    \n",
    "    trainds = (trainds\n",
    "               .map(preproc.read_from_tfr, num_parallel_calls=num_parallel)\n",
    "               .map(_preproc_img_label, num_parallel_calls=num_parallel)\n",
    "              )\n",
    "    return trainds\n",
    "\n",
    "def create_preproc_image(filename):\n",
    "    preproc = _Preprocessor()\n",
    "    img = preproc.read_from_jpegfile(filename)\n",
    "    return preproc.preprocess(img)\n",
    "\n",
    "class RandomColorDistortion(tf.keras.layers.Layer):\n",
    "    def __init__(self, contrast_range=[0.5, 1.5], \n",
    "                 brightness_delta=[-0.2, 0.2], **kwargs):\n",
    "        super(RandomColorDistortion, self).__init__(**kwargs)\n",
    "        self.contrast_range = contrast_range\n",
    "        self.brightness_delta = brightness_delta\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        if not training:\n",
    "            return images\n",
    "        \n",
    "        contrast = np.random.uniform(\n",
    "            self.contrast_range[0], self.contrast_range[1])\n",
    "        brightness = np.random.uniform(\n",
    "            self.brightness_delta[0], self.brightness_delta[1])\n",
    "        \n",
    "        images = tf.image.adjust_contrast(images, contrast)\n",
    "        images = tf.image.adjust_brightness(images, brightness)\n",
    "        images = tf.clip_by_value(images, 0, 1)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up the reading of data\n",
    "\n",
    "To try it out, we'll simply read through the data several times and compute some quantity on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_dataset(ds, nepochs):\n",
    "    lowest_mean = tf.constant(1.)\n",
    "    for epoch in range(nepochs):\n",
    "        thresh = np.random.uniform(0.3, 0.7) # random threshold\n",
    "        count = 0\n",
    "        sumsofar = tf.constant(0.)\n",
    "        for (img, label) in ds:\n",
    "            # mean of channel values > thresh\n",
    "            mean = tf.reduce_mean(tf.where(img > thresh, img, 0))\n",
    "            sumsofar = sumsofar + mean\n",
    "            count = count + 1\n",
    "            if count%100 == 0:\n",
    "                print('.', end='')\n",
    "        mean = sumsofar/count\n",
    "        print(mean)\n",
    "        if mean < lowest_mean:\n",
    "            lowest_mean = mean\n",
    "    return lowest_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN_SUFFIX, NUM_EPOCHS = '-0000[01]-*', 2 # 2 files, 2 epochs\n",
    "#PATTERN_SUFFIX, NUM_EPOCHS = '-*', 20 # 16 files, 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...tf.Tensor(0.22762734, shape=(), dtype=float32)\n",
      "...tf.Tensor(0.21017572, shape=(), dtype=float32)\n",
      "CPU times: user 7.03 s, sys: 500 ms, total: 7.53 s\n",
      "Wall time: 7.99 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.21017572>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ds = create_preproc_dataset_plain(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ")\n",
    "loop_through_dataset(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...tf.Tensor(0.14244522, shape=(), dtype=float32)\n",
      "...tf.Tensor(0.18533988, shape=(), dtype=float32)\n",
      "CPU times: user 7.93 s, sys: 375 ms, total: 8.3 s\n",
      "Wall time: 5.94 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.14244522>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# parallel map\n",
    "ds = create_preproc_dataset_parallelmap(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ")\n",
    "loop_through_dataset(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "first half\n",
      "second half\n",
      "...tf.Tensor(0.12316246, shape=(), dtype=float32)\n",
      "...tf.Tensor(0.15402032, shape=(), dtype=float32)\n",
      "CPU times: user 7.86 s, sys: 497 ms, total: 8.35 s\n",
      "Wall time: 5.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.12316246>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# with interleave\n",
    "ds = create_preproc_dataset_interleave(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX,\n",
    "    num_parallel=None\n",
    ")\n",
    "loop_through_dataset(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "...tf.Tensor(0.18058446, shape=(), dtype=float32)\n",
      "...tf.Tensor(0.14600855, shape=(), dtype=float32)\n",
      "CPU times: user 7.99 s, sys: 443 ms, total: 8.44 s\n",
      "Wall time: 5.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.14600855>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# with interleave and parallel mpas\n",
    "ds = create_preproc_dataset_interleave(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX,\n",
    "    num_parallel=AUTOTUNE\n",
    ")\n",
    "loop_through_dataset(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I did this, this is what I got:\n",
    "\n",
    "| Method                 | CPU time    | Wall time    |\n",
    "| ---------------------- | ----------- | ------------ |\n",
    "| Plain                  | 7.53s       | 7.99s        |\n",
    "| Parallel Map           | 8.30s       | 5.94s        |\n",
    "| Interleave             | 8.60s       | 5.47s        |\n",
    "| Interleave+Parallel Map| 8.44s       | 5.23s        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML model\n",
    "\n",
    "The computation above was pretty cheap involving merely adding up all the pixel values.\n",
    "What happens if we need a bit more complexity (gradient calc, etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple_model(ds, nepochs):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(\n",
    "            input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)),\n",
    "        #tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "    model.fit(ds, epochs=nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 384.5950 - accuracy: 0.2841\n",
      "Epoch 2/2\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 260.8144 - accuracy: 0.3983\n",
      "CPU times: user 9.12 s, sys: 796 ms, total: 9.91 s\n",
      "Wall time: 9.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = create_preproc_dataset_plain(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").batch(1)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 378.1755 - accuracy: 0.2646\n",
      "Epoch 2/2\n",
      "359/359 [==============================] - 4s 10ms/step - loss: 277.4931 - accuracy: 0.4067\n",
      "CPU times: user 9.97 s, sys: 718 ms, total: 10.7 s\n",
      "Wall time: 8.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parallel map\n",
    "ds = create_preproc_dataset_parallelmap(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").batch(1)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 359.4355 - accuracy: 0.3008\n",
      "Epoch 2/2\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 296.0292 - accuracy: 0.3928\n",
      "CPU times: user 9.7 s, sys: 825 ms, total: 10.5 s\n",
      "Wall time: 7.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with interleave\n",
    "ds = create_preproc_dataset_interleave(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX,\n",
    "    num_parallel=None\n",
    ").batch(1)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 403.3262 - accuracy: 0.2423\n",
      "Epoch 2/2\n",
      "359/359 [==============================] - 3s 8ms/step - loss: 260.8356 - accuracy: 0.4290\n",
      "CPU times: user 9.6 s, sys: 728 ms, total: 10.3 s\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with interleave and parallel mpas\n",
    "ds = create_preproc_dataset_interleave(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX,\n",
    "    num_parallel=AUTOTUNE\n",
    ").batch(1)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the improvement remains:\n",
    "\n",
    "| Method                 | CPU time    | Wall time    |\n",
    "| -----------------------| ----------- | ------------ |\n",
    "| Plain                  | 9.91s        | 9.39s        |\n",
    "| Parallel Map           | 10.7s        | 8.17s        |\n",
    "| Interleave             | 10.5s        | 7.54s        |\n",
    "| Interleave+Parallel Map| 10.3s        | 7.17s        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up the handling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alias to the more efficient one\n",
    "def create_preproc_dataset(pattern):\n",
    "    return create_preproc_dataset_interleave(pattern, num_parallel=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 387.4389 - accuracy: 0.2813\n",
      "Epoch 2/2\n",
      "359/359 [==============================] - 3s 9ms/step - loss: 279.8046 - accuracy: 0.3760\n",
      "CPU times: user 10.5 s, sys: 899 ms, total: 11.4 s\n",
      "Wall time: 8.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add prefetching\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").prefetch(AUTOTUNE).batch(1)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "45/45 [==============================] - 3s 60ms/step - loss: 113.6279 - accuracy: 0.2702\n",
      "Epoch 2/2\n",
      "45/45 [==============================] - 3s 56ms/step - loss: 120.0435 - accuracy: 0.2758\n",
      "CPU times: user 8.97 s, sys: 590 ms, total: 9.56 s\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add batching of different sizes\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").prefetch(AUTOTUNE).batch(8)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 97.3240 - accuracy: 0.2507\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - 2s 105ms/step - loss: 41.4950 - accuracy: 0.3900\n",
      "CPU times: user 8.97 s, sys: 939 ms, total: 9.9 s\n",
      "Wall time: 6.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add batching of different sizes\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").prefetch(AUTOTUNE).batch(16)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 2s 187ms/step - loss: 121.8208 - accuracy: 0.2423\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 2s 185ms/step - loss: 51.0977 - accuracy: 0.3259\n",
      "CPU times: user 8.78 s, sys: 902 ms, total: 9.68 s\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add batching of different sizes\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").prefetch(AUTOTUNE).batch(32)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 3s 213ms/step - loss: 106.7971 - accuracy: 0.2423\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 66.2376 - accuracy: 0.3203\n",
      "CPU times: user 5.16 s, sys: 1 s, total: 6.16 s\n",
      "Wall time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add caching: always do this optimization last.\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").cache().batch(32)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 2s 192ms/step - loss: 126.8334 - accuracy: 0.2340\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 51.4512 - accuracy: 0.3287\n",
      "CPU times: user 5.01 s, sys: 756 ms, total: 5.76 s\n",
      "Wall time: 4.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add caching: always do this optimization last.\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").prefetch(AUTOTUNE).cache().batch(32)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 2 files.\n",
      "Epoch 1/2\n",
      "12/12 [==============================] - 2s 208ms/step - loss: 148.2066 - accuracy: 0.2507\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 71.6666 - accuracy: 0.3064\n",
      "CPU times: user 4.95 s, sys: 692 ms, total: 5.65 s\n",
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add caching: always do this optimization last.\n",
    "ds = create_preproc_dataset(\n",
    "    'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX\n",
    ").cache().prefetch(AUTOTUNE).batch(32)\n",
    "train_simple_model(ds, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding to the previous table:\n",
    "\n",
    "| Method                 | CPU time    | Wall time    |\n",
    "| -----------------------| ----------- | ------------ |\n",
    "| Plain                  | 9.91s        | 9.39s        |\n",
    "| Parallel Map           | 10.7s        | 8.17s        |\n",
    "| Interleave             | 10.5s        | 7.54s        |\n",
    "| Interleave+Parallel Map| 10.3s        | 7.17s        |\n",
    "| Interleave + Parallel, and then adding:         | - | - |\n",
    "| Prefetch           | 11.4s       | 8.09s        |\n",
    "| Batch size  8      | 9.56s       | 6.90s        |\n",
    "| Batch size 16      | 9.90s       | 6.70s        |\n",
    "| Batch size 32      | 9.68s       | 6.37s        |\n",
    "| Interleave + Parallel + batchsize 32, and then adding: | - | - |\n",
    "| Cache              | 6.16s       | 4.36s        |\n",
    "| Prefetch + Cache   | 5.76s       | 4.04s        |\n",
    "| Cache + Prefetch   | 5.65s       | 4.19s        |\n",
    "\n",
    "So, the best option is:\n",
    "<pre>\n",
    "ds = create_preproc_dataset_interleave(pattern, num_parallel=AUTOTUNE).prefetch(AUTOTUNE).cache().batch(32)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply efficiency improvements\n",
    "\n",
    "Interleaving, parallel calls, prefetch, batching\n",
    "\n",
    "Caching is not a good idea on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATTERN_SUFFIX, NUM_EPOCHS = '-0000[0123]-*', 3 # small\n",
    "PATTERN_SUFFIX, NUM_EPOCHS = '-*', 20 # full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(batch_size = 32,\n",
    "                       lrate = 0.001,\n",
    "                       l1 = 0.,\n",
    "                       l2 = 0.,\n",
    "                       num_hidden = 16):\n",
    "    regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "    \n",
    "    train_dataset = create_preproc_dataset_interleave(\n",
    "        'gs://practical-ml-vision-book/flowers_tfr/train' + PATTERN_SUFFIX,\n",
    "        num_parallel=AUTOTUNE\n",
    "    ).prefetch(AUTOTUNE).batch(batch_size)\n",
    "    eval_dataset = create_preproc_dataset_interleave(\n",
    "        'gs://practical-ml-vision-book/flowers_tfr/valid' + PATTERN_SUFFIX,\n",
    "        num_parallel=AUTOTUNE\n",
    "    ).prefetch(AUTOTUNE).batch(batch_size)\n",
    "\n",
    "    layers = [\n",
    "      tf.keras.layers.experimental.preprocessing.RandomCrop(\n",
    "          height=IMG_HEIGHT//2, width=IMG_WIDTH//2,\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          name='random/center_crop'\n",
    "      ),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "          mode='horizontal',\n",
    "          name='random_lr_flip/none'\n",
    "      ),\n",
    "      RandomColorDistortion(name='random_contrast_brightness/none'),\n",
    "      hub.KerasLayer(\n",
    "          \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "      tf.keras.layers.Dense(num_hidden,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            activation=tf.keras.activations.relu,\n",
    "                            name='dense_hidden'),\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "    ]\n",
    "\n",
    "    model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    history = model.fit(train_dataset, validation_data=eval_dataset, epochs=NUM_EPOCHS)\n",
    "    training_plot(['loss', 'accuracy'], history)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "jlxxxpeaT6ea",
    "outputId": "ad4f09e8-bc33-4c92-dc47-5fc73ec12f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaving the reading of 16 files.\n",
      "Interleaving the reading of 2 files.\n",
      "Model: \"flower_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random/center_crop (RandomCr (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_lr_flip/none (RandomF (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast_brightness/n (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenet_embedding (KerasLa (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_hidden (Dense)         (None, 16)                20496     \n",
      "_________________________________________________________________\n",
      "flower_prob (Dense)          (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 2,278,565\n",
      "Trainable params: 20,581\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "92/92 [==============================] - 34s 371ms/step - loss: 0.8167 - accuracy: 0.6919 - val_loss: 0.6089 - val_accuracy: 0.7617\n",
      "Epoch 2/20\n",
      "92/92 [==============================] - 30s 330ms/step - loss: 0.4434 - accuracy: 0.8480 - val_loss: 0.5070 - val_accuracy: 0.8212\n",
      "Epoch 3/20\n",
      "92/92 [==============================] - 28s 307ms/step - loss: 0.3874 - accuracy: 0.8626 - val_loss: 0.4560 - val_accuracy: 0.8368\n",
      "Epoch 4/20\n",
      "92/92 [==============================] - 29s 311ms/step - loss: 0.3476 - accuracy: 0.8800 - val_loss: 0.4511 - val_accuracy: 0.8161\n",
      "Epoch 5/20\n",
      "92/92 [==============================] - 30s 323ms/step - loss: 0.3209 - accuracy: 0.8920 - val_loss: 0.4516 - val_accuracy: 0.8342\n",
      "Epoch 6/20\n",
      "92/92 [==============================] - 29s 316ms/step - loss: 0.3125 - accuracy: 0.8906 - val_loss: 0.4229 - val_accuracy: 0.8472\n",
      "Epoch 7/20\n",
      "92/92 [==============================] - 28s 308ms/step - loss: 0.3099 - accuracy: 0.8903 - val_loss: 0.4300 - val_accuracy: 0.8394\n",
      "Epoch 8/20\n",
      "92/92 [==============================] - 28s 304ms/step - loss: 0.2850 - accuracy: 0.9039 - val_loss: 0.4110 - val_accuracy: 0.8316\n",
      "Epoch 9/20\n",
      "92/92 [==============================] - 28s 309ms/step - loss: 0.2673 - accuracy: 0.9018 - val_loss: 0.4198 - val_accuracy: 0.8446\n",
      "Epoch 10/20\n",
      "92/92 [==============================] - 29s 310ms/step - loss: 0.2864 - accuracy: 0.8995 - val_loss: 0.4210 - val_accuracy: 0.8420\n",
      "Epoch 11/20\n",
      "92/92 [==============================] - 28s 305ms/step - loss: 0.2584 - accuracy: 0.9056 - val_loss: 0.4465 - val_accuracy: 0.8394\n",
      "Epoch 12/20\n",
      "92/92 [==============================] - 28s 308ms/step - loss: 0.2515 - accuracy: 0.9076 - val_loss: 0.4327 - val_accuracy: 0.8472\n",
      "Epoch 13/20\n",
      "92/92 [==============================] - 28s 309ms/step - loss: 0.2607 - accuracy: 0.9083 - val_loss: 0.4279 - val_accuracy: 0.8420\n",
      "Epoch 14/20\n",
      "92/92 [==============================] - 28s 301ms/step - loss: 0.2329 - accuracy: 0.9138 - val_loss: 0.4362 - val_accuracy: 0.8575\n",
      "Epoch 15/20\n",
      "92/92 [==============================] - 28s 307ms/step - loss: 0.2306 - accuracy: 0.9168 - val_loss: 0.4519 - val_accuracy: 0.8316\n",
      "Epoch 16/20\n",
      "92/92 [==============================] - 28s 303ms/step - loss: 0.2271 - accuracy: 0.9240 - val_loss: 0.4291 - val_accuracy: 0.8472\n",
      "Epoch 17/20\n",
      "92/92 [==============================] - 29s 315ms/step - loss: 0.2194 - accuracy: 0.9182 - val_loss: 0.4727 - val_accuracy: 0.8472\n",
      "Epoch 18/20\n",
      "92/92 [==============================] - 28s 308ms/step - loss: 0.2122 - accuracy: 0.9254 - val_loss: 0.4143 - val_accuracy: 0.8472\n",
      "Epoch 19/20\n",
      "92/92 [==============================] - 30s 323ms/step - loss: 0.2225 - accuracy: 0.9226 - val_loss: 0.4465 - val_accuracy: 0.8264\n",
      "Epoch 20/20\n",
      "92/92 [==============================] - 28s 304ms/step - loss: 0.2042 - accuracy: 0.9294 - val_loss: 0.4450 - val_accuracy: 0.8497\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these efficiencies, an epoch takes around 30s (compared to 120s before)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model, then load it to make predictions\n",
    "\n",
    "This way, we don't have to have the model in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "shutil.rmtree('export', ignore_errors=True)\n",
    "os.mkdir('export')\n",
    "model.save('export/flowers_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls export/flowers_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --tag_set serve --signature_def serving_default --dir export/flowers_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "HEh_vh0vvnNd",
    "outputId": "e43ebba2-fe2b-4a53-8b94-32598c021498"
   },
   "outputs": [],
   "source": [
    "# Call model.predict() on a few images in evaluation dataset\n",
    "def plot_predictions(model, pattern):\n",
    "    dataset = create_preproc_dataset_plain(pattern)\n",
    "    f, ax = plt.subplots(3, 5, figsize=(25,15))\n",
    "    for idx, (img, label) in enumerate(dataset.take(15)):\n",
    "        ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "        batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "        batch_pred = model.predict(batch_image)\n",
    "        pred = batch_pred[0]\n",
    "        label = CLASS_NAMES[label.numpy()]\n",
    "        pred_label_index = tf.math.argmax(pred).numpy()\n",
    "        pred_label = CLASS_NAMES[pred_label_index]\n",
    "        prob = pred[pred_label_index]\n",
    "        ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "\n",
    "serving_model = tf.keras.models.load_model('export/flowers_model')\n",
    "plot_predictions(serving_model, 'gs://practical-ml-vision-book/flowers_tfr/valid-*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## but actually, for prediction, we won't have TensorFlow Records.\n",
    "## this is how we'd predict for individual images\n",
    "## (actually, we'll create a serving function: we'll look at that in a later chapter)\n",
    "filenames = [\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/98992760_53ed1d26a9.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9939430464_5f5861ebab.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/dandelion/9965757055_ff01b5ee6f_n.jpg'\n",
    "]\n",
    "label = 'dandelion'\n",
    "input_images = [create_preproc_image(f) for f in filenames]\n",
    "f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "for idx, img in enumerate(input_images):\n",
    "    ax[idx].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = serving_model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duu8mX3iXANE"
   },
   "source": [
    "## License\n",
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
